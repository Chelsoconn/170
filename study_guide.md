

1. **Give an overview of the Link/Data Layer**

   In the OSI model, the Data Link Layer is Layer 2 and comes in between the Physical Layer(1) and the Network Layer(3).  In the Internet Protocol Suite, the Link Layer is 1.	

    * The layer is an interface between the workings of the physical network and the more logical layers above.

    * The most commonly used protocol at this later is the `Ethernet` protocol

      * Ethernet cables connect devices on the network such as computers, switches, and routers.

      * The technical specification of these cables is governed by the same [IEEE standards](https://standards.ieee.org/standard/802_3-2018.html) that include the Ethernet communication protocols that operate at this layer of the network.

        Two of the most important aspects of Ethernet are `*framing and addressing.*`

2. **What is included in an Ethernet frame?**

    	- DATA PAYLOAD field is used as an encapsulation mechanism for the layer 
    		- An Ethernet Frame is structured data. 
    		- Important parts are Destination MAC address, Source MAC address and Data Payload 
    		- Interframe Gaps (IFG)- brief pause between transmission of each frame, which permits the reciever to prepare for the next frame. Contributes to the latency Transmission Delay
    		- IEEE 802.3 Ethernet Standard- describes structure of frame 
    		- The main elements to focus on are the Data Payload field being used as an encapsulation mechanism for the layer above, and the MAC Address fields being used to direct the frame between network devices. These particular fields exist across all the different Ethernet standards.

![Graphic showing structure of an Ethernet Frame](https://da77jsbdz4r05.cloudfront.net/images/ls170/data-link-layer-frame-structure.png)

Ethernet frames are a Protocol Data Unit, and encapsulate data from the Internet/ Network layer above. This is the lowest level of encapsulation.Ethernet Frame adds logical structure to the physical binary data. Data in this frame are still in bits, but the structure defines shich bits are actually the data payload, which are the metadata to be used in the process of transporting the frame. An ethernet- compliant network device is able to identify the different parts of the frame due to the fact that different 'fields' of data have specific lengths in bytes and appear in a set order.

- **Preamble and SFD:** The Preamble and Start of Frame Delimiter (SFD/ SOF) generally aren't considered part of the actual frame but are sent just prior to the frame as a synchronization measure which notifies the receiving device to expect frame data and then identify the start point of that data. The preamble is seven bytes (56 bits) long and the SFD is one byte (eight bits). Both use a repeated pattern that can be recognised by the receiving device, which then knows that the data following after is the frame data.
- **Source and Destination MAC address:** The next two fields, each six bytes (48 bits) long, are the source and destination MAC addresses. The source address is the address of the device which created the frame (as we'll see later on in this assignment, this can change at various points along the data's journey). The destination MAC address is the address of the device for which the data is ultimately intended. MAC Addresses are a key part of the Ethernet protocol; we'll look at them in more detail shortly.
- **Length:** the next field is two bytes (16 bits) in length. It is used to indicate the size of the Data Payload.
- **DSAP, SSAP, Control:** The next three fields are all one byte (8 bits) in length. The DSAP and SSAP fields identify the Network Protocol used for the Data Payload. The Control field provides information about the specific communication mode for the frame, which helps facilitate flow control.
- **Data Payload:** the data payload field can be between 42 and 1497 bytes in length. It contains the data for the entire Protocol Data Unit (PDU) from the layer above, an IP Packet for example.
- **Frame Check Sequence (FCS):** The final four bytes (32 bits) of an Ethernet Frame is the Frame Check Sequence. This is a checksum generated by the device which creates the frame. It is calculated from the frame data using an algorithm such as a cyclic redundancy check. The receiving device uses the same algorithm to generate a FCS and then compares this to the FCS in the sent frame. If the two don't match, then the frame is dropped. Ethernet doesn't implement any kind of retransmission functionality for dropped frames; it is the responsibility of higher level protocols to manage retransmission of lost data if this is a requirement of the protocol.

1. **Give an overview of the Internet/Network Layer and it's role.**

   OSI- network layer 3 between Data Link and Transport 

   TCP/ IP- Internet later is 2 between Link and Transport- PREDOMINANTLY used 

   - primary function of protocols at this layer is to facilitate communication between hosts (e.g. computers) on different networks.- internetwork comm.

2. **What is IP?**

   Internet Protocol is the predominant protocol used for Internet/Network Layer.

   Two versions - 

    	1) *IPv4*, IPv6
    	 	1) Routing capabilities via IP addressing 
    	 	2) Encapsulation of data into packets
    	 	3) PDU within the IP protocol is a `packet`- comprised of a data payload and a header. Data payload is the PDU from Transport. Data is in bits like in Ethernet frame. Logical separation is determined by the set size of each field in bits and the order within the packet. 

We won't describe every field in the header, but some of the more important ones to be aware of are:

- **Version:** this indicates the version of the Internet Protocol used, e.g. IPv4

- **ID, Flags, Fragment Offset:** these fields are related to fragmentation. If the Transport layer PDU is too large to be sent as a single packet, it can be fragmented, sent as multiple packets, and then reassembled by the recipient.

- **TTL:** every packet has a Time to Live (TTL) value. This is to ensure that any packets which don't reach their destination for some reason aren't left to endlessly bounce around the network. The TTL indicates the maximum number of network 'hops' a packet can take before being dropped. At each hop, the router which processes and forwards the packet will decrement the TTL value by one.

- **Protocol:** this indicates the protocol used for the Data Payload, e.g. TCP, UDP, etc.

- **Checksum:** this is an error checking value generated via an algorithm. The destination device generates a value using the same algorithm and if it doesn't match, it drops the packet. IP doesn't manage retransmission of dropped packets. This is left to the layers above to implement.

- **Source Address:** the 32-bit IP address of the source (sender) of the packet

- **Destination Address:** the 32-bit IP address of the destination (intended recipient) of the packet

  

1. **What is DNS and how does it work?**

   [**Domain name system**](https://www.techtarget.com/searchnetworking/definition/domain-name-system)**.** DNS is a database that includes a website's domain name, which people  use to access the website, and its corresponding IP addresses, which  devices use to locate the website. DNS translates the domain name into  IP addresses, and these translations are included within the DNS.  Servers can [cache DNS data](https://www.computerweekly.com/news/252464579/DNS-a-security-opportunity-not-to-be-overlooked-says-Nominet), which is required to access the websites. DNS also includes the DNS  protocol, which is within the IP suite and details the specifications  DNS uses to translate and communicate.

   DNS is important because it can quickly provide users with  information, as well as access to remote hosts and resources across the  internet.

   

2. **How do port numbers and IP addresses work together?**

   An IP address along with a port number create a socket.  A socket is a communications connection point (endpoint) that you can name and address in a network. Socket programming shows how to use socket APIs (application programming interface) to establish communication links between remote and local processes.  A socket is bound to a port number so that the TCP layer can identify the application that  data is destined to be sent to. An endpoint is a combination of an IP  address and a port number.

   

3. **What is a checksum and what is it used for? How is it used?**

   An error checking value generated via an algorithm. The destination device generates a value using the same algorithm and if it doesn't match, it drops the packet. IP doesn't manage retransmission of dropped packets. This is left to the layers above to implement.



***LESSON 1 SUMMARY***

#  Summary

- *Ethernet* is a set of standards and protocols that enables *communication between devices on a local network*.
- Ethernet uses a Protocol Data Unit called a Frame.
- Ethernet uses *MAC addressing* to identify devices connected to the local network.
- The *Internet Protocol* (IP) is the predominant protocol used for *inter-network communication*.
- There are two versions of IP currently in use: IPv4 and IPv6.
- The *Internet Protocol* uses a system of addressing (IP Addressing) to *direct data between one device and another across networks*.
- IP uses a Protocol Data Unit called a Packet.



1. **Give an overview of the Transport Layer.**

   running multiple apps at once- We can perhaps think of these different applications or processes as distinct *channels* for communication on a host machine.

   So, although we have multiple communication channels *on* a host, with IP addresses we only have a single channel *between* hosts. What we need is a way to transmit these multiple data inputs over this single host-to-host channel and then somehow separate them out at the other end.

   Getting data from Application layer and breaking it into packets, and attaching meta-info (source dest. ports) 

   Destination port numbers are included in the PDU (Protocol Data Unit) for the Transport Layer.  The name, and exact structure, of these PDUs varies according to the Transport Protocol used, but what they have in common is that they include these two pieces of information.

![Simple graphic of a transport layer PDU showing source and destination ports](https://da77jsbdz4r05.cloudfront.net/images/ls170/transport-comms-between-processes-simple-pdu.png)

* Data from the application layer is encapsulated as the data payload in this PDU, and the source and destination port numbers within the PDU can be used to direct that data to specfic processes on a host. The entire PDU is then encapsulated as the data payload in an IP packet.
*  The IP address and the port number *together* are what enables end-to-end communication between specific applications on different machines. The combination of IP address and port number information can be thought of as defining a *communication end-point*. This communication end-point is generally referred to as a *socket*.
* **TCP protocol** - 

  * The Transmission Control Protocol (TCP) is one of the corner-stones of the Internet. One of the key characteristics of this protocol is the fact that it provides reliable data transfer. In fact, reliability is listed as a key element of TCP operation as defined in [RFC793](https://www.ietf.org/rfc/rfc793.txt).

  > The TCP must recover from data that is damaged, lost, duplicated, or delivered out of order by the internet communication system.

  - What TCP essentially provides is the abstraction of reliable network communication on top of an unreliable channel. What this abstraction does is to hide much of the complexity of reliable network communication from the application layer: data integrity, de-duplication, in-order delivery, and retransmission of lost data.
  - Reliability isn't the only thing that TCP provides. It also provides data encapsulation and multiplexing through the use of TCP Segments.



1. **What are the fundamental elements of reliable protocol?**

   * The possibility of losing data and it not being replaced means that the network up to and including the Internet Protocol is effectively an *unreliable communication channel*.  What we need to do is develop a system of rules, or a protocol, to ensure that all the data that is sent is received at the other end and in the correct order. What would such a system of rules look like?

   * Problem: Messages can become corrupt or lost, how do you ensure the message has been successfully received?

      * Solution: Use an acknowledgement message
        * Rules:
          - Sender sends one message at a time
          - If message received, receiver sends an acknowledgement
          - When acknowledgement is received, sender sends next message
        * This seems like a pretty good solution, but there's a major flaw with it. There are certain situations in which the sender will never receive an acknowledgement:
          - The recipient never receives the message and so doesn't send an acknowledgement
          - The recipient receives the message and sends an acknowledgement, but the acknowledgement becomes corrupt or lost

   * Problem: what if the acknowledgement is not received?

      * Solution: re-send the message if acknowledgement not received within a certain time-frame.
        * Rules:
          - Sender sends one message at a time, and sets a timeout
          - If message received, receiver sends an acknowledgement
          - When acknowledgement is received, sender sends next message
          - If acknowledgement not received before the timeout expires, sender assumes either the message or the acknowledgement went missing and sends the same message again
        * Solving this problem has however introduced a separate problem into our system: duplication. Imagine the following scenarios:
          - The receiver receives the message and sends an acknowledgement, but the acknowledgement becomes corrupt or lost
          - The receiver receives the message and sends an acknowledgement, but the acknowledgement is delayed and the sender doesn't receive it before the timeout expires

   * Problem: the message is received but acknowledgement is not received (or not in time), resulting in a duplicate message.

      * Solution: add sequence numbers to the messages.

        * Rules:
          - Sender sends one message at a time, with a sequence number, and sets a timeout
          - If message received, receiver sends an acknowledgement which uses the sequence number of the message to indicate which message was received
          - When acknowledgement is received, sender sends next message in the sequence
          - If acknowledgement is not received before the timeout expires, sender assumes either the message or the acknowledgement went missing and sends the same message again with the same sequence number
          - If the recipient receives a message with a duplicate sequence number it assumes the sender never received the acknowledgement and so sends another acknowledgement for that sequence number and discards the duplicate

      * In order delivery: data is received in the order that it was sent

     * Error detection: corrupt data is identified using a checksum

     * Handling data loss: missing data is retransmitted based on acknowledgements and timeouts

     * Handling duplication: duplicate data is eliminated through the use of sequence numbers

       **Our protocol as it stands is reliable. Unfortunately, it's not very efficient. ** It's a "stop and wait" system and is not an efficient use of bandwidth.

       

2. **What is pipe-lining protocols? What are the benefits of it?**

   In computer networking, pipelining is the method of sending multiple data units without waiting for an acknowledgment for the first frame sent. Pipelining ensures better utilization of network resources and also increases the speed of delivery, particularly in situations where a large number of data units make up a message to be sent.

   - To improve the throughput of our protocol, we send multiple messages on after the other without waiting for acknowledgements.Reliability is still there bc we are still recieving these acknowledgments, we are just sending multiple messages at one time. 

![transport-reliability-stop-and-wait-vs-pipelining](https://da77jsbdz4r05.cloudfront.net/images/ls170/transport-reliability-stop-and-wait-vs-pipelining.png)

Both Go-back-N and Selective Repeat both use a 'window' which is the max number of messages that can be in the pipeline at any one time, and once it recieves all the acknowledgments, it moves to the next window.

![transport-reliability-windowing](https://da77jsbdz4r05.cloudfront.net/images/ls170/transport-reliability-windowing.png)

BENEFITS - The advantage of this pipelined approach is its more efficient use of available bandwidth. Instead of wasting lots of time just waiting for acknowledgements, more time is spent actually transmitting data.

Finding a balance between reliability and performance is a major part of the implementation of the Transmission Control Protocol (TCP). We'll look at this protocol in more detail in the next assignment.



1. **What is a network port?**

   A port is an identifier for a specific process running on a host. This identifier is an integer in the range 0-65535. 

   A port is NOT a physical connection. Its a logical connection thats used by programs and services to exchange info.

   Its specifically determines which program or service on a computer or server that is going to be used.

   Always associated with an IP address- work together to exchange data on a network 

2. **What is a port number?**

   - Unique number that identifies them. 

   1. 0-1023 are well-known ports. These are assigned to processes that provide commonly used network services. For example HTTP is port 80, FTP is port 20 and 21, SMTP is port 25, and so on.
   2. 1024-49151 are registered ports. They are assigned as requested by private entities. For example, companies such as Microsoft, IBM, and Cisco have ports assigned that they use to provide specific services. On some operating systems, ports in this range are also used for allocation as *ephemeral ports* on the client side.
   3. 49152-65535 are dynamic ports (sometimes known as private ports). Ports in this range cannot be registered for a specific use. They can be used for customized services or for allocation as *ephemeral ports*.

3. **What is a network socket?**

   The IP address and the port number together are what enables end-to-end communication between specific applications on different machines.  The combination of IP address and port number info can be thought of as defining a `communication end-point`- generally referred to as the socket. Ex/ 216.3.128.12:8080

   - An abstraction for an endpoint used for inter-process communication
   - At an implementation level, it can be used to refer to different specific things:
     - UNIX socket: a mechanism for communication between local processes running on the same machine.
     - Internet sockets (such as a TCP/IP socket): a mechanism for inter-process communication between networked processes (usually on different machines).
     - There *is* a distinction between the concept of a network socket and its implementation in code.

4. **Is TCP connectionless? Why?**

   Transmission Control Protocol- Connection Oritented Protocol

   Establishes connection with server after the data is broken down into packets from the application layer.

   - Check connections by running `netstat -ap TCP` in terminal
   - `TCP is an example of a connection-oriented protocol`. It requires a logical connection to be established between the two processes before data is exchanged. The connection must be maintained during the entire time that communication is taking place, then released afterwards.

5. **How do sockets on the implementation level relate to the idea of protocols being connectionless or connection-oriented?**

   -In socket programming or network programming terms though, the implementation of this concept involves instantiating *socket objects*. While implementations vary, many follow the Berkeley sockets API model. Implementations which follow this model define specific functions such as `bind()`, `listen()`, `accept()`, and `connect()`, among others.

   -The reason for this is that having a mental model of sockets being implemented as objects helps to understand how they can be used to create *connections* between applications. Some understanding of connections is necessary to comprehend the difference between connection-oriented communication and connectionless communication. 

   -By instantiating multiple socket objects, we can implement connection-oriented network communication between applications.

   ![transport-comms-between-processes-connectionless](https://da77jsbdz4r05.cloudfront.net/images/ls170/transport-comms-between-processes-connectionless.png)

   * Connectionless - In a connectionless system we could have one socket object defined by the IP address of the host machine and the port assigned to a particular process running on that machine. That object could call a `listen()` method which would allow it to wait for incoming messages directed to that particular IP/port pair. Such messages could potentially come from any source, at any time, and in any order, but that isn't a concern in a connectionless system -- it would simply process any incoming messages as they arrived and send any responses as necessary.

   

   ![transport-comms-between-processes-connection-oriented](https://da77jsbdz4r05.cloudfront.net/images/ls170/transport-comms-between-processes-connection-oriented.png)

   * Connection- Oriented - A connection-oriented system would work differently. You could have a socket object defined by the host IP and process port, just as in the connectionless system, also using a `listen()` method to wait for incoming messages; the difference in implementation would be in what happens when a message arrives. At this point we could instantiate a *new* socket object; this new socket object wouldn't just be defined by the local IP and port number, but also by the IP and port of the process/host which sent the message. This new socket object would then listen specifically for messages where all four pieces of information matched (source port, source IP, destination port, destination IP). The combination of these four pieces of information is commonly referred to as a four-tuple.  Any messages not matching this four-tuple would still be picked up by the original socket, which would then instantiate another socket object for the new connection.
     * Implementing communication in this way effectively creates a dedicated virtual connection for communication between a specific process running on one host and a specific process running on another host. The advantage of having a dedicated connection like this is that it more easily allows you to put in place rules for managing the communication such as the order of messages, acknowledgements that messages had been received, retransmission of messages that weren't received, and so on. The purpose of these types of additional communication rules is to add more reliability to the communication.

   

6. **What is a three-way handshake? What is it used for?**

   In the TCP (Transmission Control Protocol) protocol. Establishing a connection with the server. This is why TCP is a connection oriented communication. It doesn't start sending data until a connection has been established between app. processes.

   1) Client sends SYN (synchronized) packet to the server - 'Hey server I want to establish a connection with you': a TCP Segment with the `SYN` flag set to `1`
   2) Server recieves it and sends back SYN ACK (synchronized acknowledgement)- "hey I'm ready to accept the connection" : a TCP Segment with the `SYN` and `ACK` flags set to `1`
   3) Client recieves and sends back ACK (acknowledgement)- connection established! 
      1) Packet Transmission can start: a TCP Segment with the `ACK` flag set to `1`

   * the`FIN` flag is used in different process, the Four-way Handshake, used for terminating connections.

   * Upon sending the ACK, the sender can immediately start sending application data. The receiver must wait until it has received the ACK before it can send any data back to the sender. One of the main reasons for this process is to synchronise (`SYN`) the sequence numbers that will be used during the connection.
   * We want to maintain a connection state- According to RFC793
     * A connection progresses through a series of states during its lifetime. The states are: LISTEN, SYN-SENT, SYN-RECEIVED, ESTABLISHED, FIN-WAIT-1, FIN-WAIT-2, CLOSE-WAIT, CLOSING, LAST-ACK, TIME-WAIT, and the fictional state CLOSED. CLOSED is fictional because it represents the state when there is no TCB, and therefore, no connection.  Most of the time the state we are most concerned with is `ESTABLISHED`, and also `LISTEN` on the server side. The other states are related to the establishment and termination of connections.

| Client Start State | Client Action                                                | Client End State | Server Start State | Server Action                                                | Server End State |
| :----------------- | :----------------------------------------------------------- | :--------------- | :----------------- | :----------------------------------------------------------- | :--------------- |
| `CLOSED`           | Sends a `SYN` Segment                                        | `SYN-SENT`       | `LISTEN`           | Waits for a connection request                               | -                |
| `SYN-SENT`         | Waits to receive an ACK to the SYN it sent, as well as the server's `SYN` | `SYN-SENT`       | `LISTEN`           | Sends a SYN ACK Segment which serves as both it's SYN and an ACK for the client's SYN | `SYN-RECEIVED`   |
| `SYN-SENT`         | Receives the SYN ACK Segment sent by the server, and sends an ACK in response. The client is now finished with the connection establishment process | `ESTABLISHED`    | `SYN-RECEIVED`     | Waits for an ACK for the SYN it just sent                    | -                |
| `ESTABLISHED`      | Ready for data transfer. Can start sending application data. | `ESTABLISHED`    | `SYN-RECEIVED`     | Receives the ACK sent in response to its SYN. The server is now finished with the connection establishment process. | `ESTABLISHED`    |

there is an entire round-trip of latency before any application data can be exchanged. Since this hand-shake process occurs every time a TCP connection is made, this clearly has an impact on any application which uses TCP at the transport layer.  In order to help facilitate efficient data transfer once a connection is established, TCP provides mechanisms for flow control and congestion avoidance.

1. **What are multiplexing and demultiplexing?**

   In the context of a communication network, this idea of transmitting multiple signals over a single channel is known as multiplexing, with demultiplexing being the reverse process. Takes place through the use of network ports.

   

2. **What is flow control? How does it work and why do we need it?**

   In order to help facilitate efficient data transfer once a connection is established, TCP provides mechanisms for flow control and congestion avoidance.  Flow control is a mechanism to prevent the sender from overwhelming the receiver with too much data at once. The receiver will only be able to process a certain amount of data in a particular time-frame. Data awaiting processing is stored in a 'buffer'. The buffer size will depend on the amount of memory allocated according to the configuration of the OS and the physical resources available.  Each side of a connection can let the other side know the amount of data that it is willing to accept via the WINDOW field of the TCP header. This number is dynamic, and can change during the course of a connection. If the receiver's buffer is getting full it can set a lower amount in the WINDOW field of a Segment it sends to the sender, the sender can then reduce the amount of data it sends accordingly. It doesn't prevent either the sender or receiver from overwhelming the underlying network. For that task we need a different mechanism: Congestion Avoidance.

3. **How TCP prevents from receiver's buffer to get overloaded with data?**

   Flow Control and Congestion Avoidance

4. **What is congestion avoidance?**

   Network Congestion is a situation that occurs when there is more data being transmitted on the network than there is network capacity to process and transmit the data. You can perhaps think of it as similar to a gridlock of vehicles on a road network. Instead of things coming to a standstill however, the 'excess vehicles' are simply lost.  In the [last lesson](https://launchschool.com/lessons/4af196b9/assignments/b222ecfb) we looked at IP packets moving across the networks in a series of 'hops'. At each hop, the packet needs to be processed: the router at that hop runs a checksum on the packet data; it also needs to check the destination address and work out how to route the packet to the next hop on its journey to that destination. All of this processing takes time, and a router can only process so much data at once. Routers use a 'buffer' to store data that is awaiting processing, but if there is more data to be processed than can fit in the buffer, the buffer over-flows and those data packets are dropped.  As we've already seen, TCP retransmits lost data. If lots of data is lost that means lots of retransmitted data, which is inefficient. Ideally we want to keep retransmission to a minimum. TCP actually uses data loss as a feedback mechanism to detect, and avoid, network congestion; if lots of retransmissions are occurring, TCP takes this as a sign that the network is congested and reduces the size of the transmission window.

5. **What is network congestion?**

   Network Congestion is a situation that occurs when there is more data being transmitted on the network than there is network capacity to process and transmit the data. You can perhaps think of it as similar to a gridlock of vehicles on a road network. Instead of things coming to a standstill however, the 'excess vehicles' are simply lost.

6. **How do transport layer protocols enable communication between processes?**

7. **Disadvantages of TCP**

   Head-of-line blocking is a general networking concept, and isn't specific to TCP. In general terms it relates to how issues in delivering or processing one message in a sequence of messages can delay or 'block' the delivery or processing of the subsequent messages in the sequence.

   With TCP, HOL blocking can occur as a result of the fact that TCP provides for in-order delivery of segments. Although this in order delivery is one aspect of TCP's reliability, if one of the segments goes missing and needs to be retransmitted, the segments that come after it in the sequence can't be processed, and need to be buffered until the retransmission has occurred. This can lead to increased queuing delay which, as we saw in an [earlier assignment](https://launchschool.com/lessons/4af196b9/assignments/097d7577), is one of the elements of latency.

8. **Compare UDP and TCP. What are similarities, what are differences? What are pros and cons of using each one?**

   1. TCP- A TCP Segment header contains a number of different fields. As we saw earlier in this Lesson, two of these fields -- Source Port and Destination Port -- provide the multiplexing capability of the protocol. Most of the other header fields are related to the way that TCP implements reliable data transfer.

![transport-layer-tcp-segment](https://da77jsbdz4r05.cloudfront.net/images/ls170/transport-layer-tcp-segment.png)



Some of the more important fields in the header in terms of implementing reliability are:

- CHECKSUM: The Checksum provides the Error Detection aspect of TCP reliability. It is an error checking value generated by the sender using an algorithm. The receiver generates a value using the same algorithm and if it doesn't match, it drops the Segment. We've encountered Checksums already in this course, in other PDUs at other network layers such as IP Packets. Having a Checksum at the Transport Layer does render Checksums at lower layers redundant to a certain extent. IPv6 headers don't include a Checksum for this reason, based on the assumption that checksums are implemented at either the Transport or Link/ Data Link layers (or both).
- SEQUENCE NUMBER and ACKNOWLEDGEMENT NUMBER: these two fields are used together to provide for the other elements of TCP reliability such as In-order Delivery, Handling Data Loss, and Handling Duplication. The precise way in which TCP uses these fields is beyond the scope of this course, but it is essentially a more complex version of the simplified example of the Reliable Protocol we constructed in the previous assignment.

Other fields of interest in a typical header are the WINDOW SIZE field and the various Flag fields. The WINDOW SIZE field is related to Flow Control, which we will look at a bit later on. The Flag fields are one-bit boolean fields. A couple of these fields, `URG` and `PSH`, are related to how the data contained in the Segment should be treated in terms of its importance or urgency; we aren't going to go into exactly how these particular flags are used. The `SYN`, `ACK`, `FIN`, and `RST` flags are used to establish and end a TCP connection, as well as manage the state of that connection; we'll look at these in some more detail below.



UDP - 

In the previous assignment, we saw how TCP implements reliable data transfer through sequencing and retransmission of lost data, as well as providing mechanisms for flow control and congestion avoidance. So how does UDP implement all of those things? Well, basically, it doesn't. It does provide error detection.

The Protocol Data Unit (PDU) of UDP is known as a Datagram. Like all the PDUs we've looked at so far it encapsulates data from the layer above into a payload and then adds header information. If we examine the header of a UDP Datagram, we can see that it's really quite simple.

![transport-udp-datagram-header](https://da77jsbdz4r05.cloudfront.net/images/ls170/transport-udp-datagram-header.png)

Through the use of the Source and Destination Port numbers, UDP provides multiplexing in the same way that TCP does. Unlike TCP however, it doesn't do anything to resolve the inherent unreliability of the layers below it. In fact, it's probably easier to define UDP by what it *doesn't* do (particularly in comparison with TCP) than by what it *does* do.

- It provides no guarantee of message delivery
- It provides no guarantee of message delivery order
- It provides no built-in congestion avoidance or flow-control mechanisms
- It provides no connection state tracking, since it is a connectionless protocol

his simplicity provides two things to a software engineer: speed and flexibility.

UDP is a connectionless protocol. Applications using UDP at the Transport layer can just start sending data without having to wait for a connection to be established with the application process of the receiver. In addition to this, the lack of acknowledgements and retransmissions means that the actual data delivery itself is faster; once a datagram is sent it doesn't have to be sent again. Latency is less of an issue since without acknowledgements data essentially just flows one way: from sender to receiver. The lack of in-order delivery also removes the issue of Head-of-line blocking (at least at the Transport layer).  It's likely that someone building a UDP-based application will want to implement some of the services that UDP doesn't natively provide. Which services those would be, and the way they're implemented, would be up to whoever was building the application though. For example, you might want your application to have in-order delivery, but at the same time not be worried about the occasional piece of lost data. You could implement sequencing, but choose not to implement data retransmission. It is left to the software engineer to decide which services to include. These services can then be implemented at the application lever, effectively using UDP as a 'base template' to build on.  Ex/ video calls, gaming 

While UDP provides a lot of flexibility and freedom, with that freedom comes a certain amount of responsibility. There are various best practices that should be adhered to. For example, it would be expected that your UDP-based application implements some form of congestion avoidance in order to prevent it overwhelming the network.



***SUMMARY*** 

- *Multiplexing* and *demultiplexing* provide for the transmission of *multiple signals over a single channel*
- Multiplexing is enabled through the use of *network ports*
- Network sockets can be thought of as a *combination of IP address and port number*
- At the *implementation level*, sockets can also be *socket objects*
- The underlying network is *inherently unreliable*. If we want reliable data transport we need to implement a system of rules to enable it.
- *TCP* is a *connection-oriented* protocol. It establishes a connection using the *Three-way-handshake*
- TCP provides reliability through *message acknowledgement* and *retransmission*, and *in-order delivery*.
- TCP also provides *Flow Control* and *Congestion Avoidance*
- The main *downsides of TCP* are the *latency overhead of establishing a connection*, and the potential *Head-of-line blocking* as a result of in-order delivery.
- *UDP* is a very simple protocol compared to TCP. It provides *multiplexing*, but no reliability, no in-order delivery, and no congestion or flow control.
- *UDP* is *connectionless*, and so doesn't need to establish a connection before it starts sending data
- Although it is unreliable, the *advantage of UDP* is *speed* and *flexibility*.



1. **What does it mean that network reliability is engineered?**

   rely on protocols that make up the layers 

2. **Give an overview of the Application Layer.**

   Both the TCP/IP model and the OSI model define an Application layer as the topmost layer in their respective layered systems (the Session layer and the Presentation layer also in OSI). Something to be clear about here is that the application layer is not the *application itself*, but rather a set of protocols which provide communication services to applications.

   One thing both models have in common however is that the protocols which exist at the Application layer are the ones with which the application most directly interacts. That's not to say that networked applications are limited to interacting with only Application layer protocols. You can see many applications interacting with Transport layer protocols by, for example, opening a TCP socket. However, it is much less common to build applications which interact directly with protocols below the Transport layer.

   Application layer protocols rely on the protocols at the layers below them to ensure that a message gets to where it is supposed to, and focus instead on the structure of that message and the data that it should contain.

   We can perhaps think of Application layer protocols as being the rules for how applications talk to each other at a syntactical level. Different types of applications have different requirements with regards to how they communicate at a syntactical level, and so as a result there are many different protocols which exist at the application layer. For example, the rules for how an email client communicates with an email server will be different from the rules for how a web browser communicates with a web server, because emails and web pages are fundamentally different things serving different purposes.

3. **What is HTML?**

   - Primary protocol used for communication on the Web. 
     - Internet is a network of networks (infrastructure that enables inter-network communication, both in terms of the physical network and the lower-level protocols that control its use) while the web is a service that can be accessed via the internet.
     - In simple terms it is a vast information system comprised of resources which are navigable by means of a URL (Uniform Resource Locator). HTTP is closely tied, both historically and functionally, to the web as we know it. It is the primary means by which applications interact with the resources which make up the web.
     - The means of providing that uniformity in the earliest incarnation of the Web was essentially a combination of three technologies or concepts: HTML, URIs, and HTTP.
     - **Hypertext Markup Language** (HTML) was the means by which the resources in this system should be uniformly structured. This early version of HTML was intended for structuring text documents using headings, paragraphs, and lists. It was very basic, containing only 18 elements. The most revolutionary of these elements was the anchor elements `<A>`, which uses a `href` attribute to provide a link from one resource to another. We'll explore HTML in a lot more detail in a later course.

4. **DNS**

   Mapping from URL to IP address is handled by the Domain Name System or **DNS**. DNS is a distributed database which translates domain names like `www.google.com` to an IP address, so that the IP address can then be used to make a request to the server. Stated differently, it keeps track of domain names and their corresponding IP addresses on the Internet. So an address like `www.google.com` might be resolved to an IP address `197.251.230.45`.  Stored on computers called **DNS servers**.

5. **What is a URL and what components does it have?**

   * It is the mechanism used by [browsers](https://developer.mozilla.org/en-US/docs/Glossary/Browser) to retrieve any published resource on the web.
   * **URL** stands for *Uniform Resource Locator*. A URL is nothing more than the address of a given unique resource on the Web. In theory, each valid URL points to a unique resource. Such resources can be an HTML page, a CSS document, an image, etc. In practice, there are some exceptions, the most common being a URL pointing to a resource that no longer exists or that has moved. As the resource represented by the URL and the URL itself are handled by the Web server, it is up to the owner of the web server to carefully manage that resource and its associated URL.
   * Enter a URL like [http://www.google.com](http://www.google.com/) into your web browser's address bar.
   * The browser creates an HTTP request, which is packaged up and sent to your device's network interface.
   * If your device already has a record of the IP address for the domain name in its DNS cache, it will use this cached address. If the IP address isn't cached, a DNS request will be made to the Domain Name System to obtain the IP address for the domain.
   * The packaged-up HTTP request then goes over the Internet where it is directed to the server with the matching IP address.
   * The remote server accepts the request and sends a response over the Internet back to your network interface which hands it to your browser.
   * Finally, the browser displays the response in the form of a web page.

![mdn-url-all](https://developer.mozilla.org/en-US/docs/Learn/Common_questions/What_is_a_URL/mdn-url-all.png)

	1) http: The scheme. It always comes before the colon and two forward slashes and tells the web client how to access the resource. In this case it tells the web client to use the Hypertext Transfer Protocol or HTTP to make a request. Other popular URL schemes are ftp, mailto or git. You may sometimes see this part of the URL referred to as the protocol, and there is a connection between the two things in that the scheme can indicate which protocol (or system of rules) should be used to access the resource; in the context of of a URL however, the correct term for this component is the scheme.
	
	2)  The host. It tells the client where the resource is hosted or located.Building then you want to go to a department "the path"
	
	3) The port or port number. It is only required if you want to use a port other than the default.  Unless a different port number is specified, port 80 will be used by default in normal HTTP requests. To use anything other than the default, one has to specify it in the URL.
	
	4)  The path. It shows what local resource is being requested. This part of the URL is optional.
	
	5) The query string, which is made up of query parameters. It is used to send data to the server. This part of the URL is also optional.

1. **What is a Query string? What it is used for?**

![Query String Components](https://d186loudes4jlv.cloudfront.net/http/images/query_string_components.png)

| Query String Component | Description                                                  |
| :--------------------- | :----------------------------------------------------------- |
| ?                      | This is a reserved character that marks the start of the query string |
| search=ruby            | This is a parameter name/value pair.                         |
| &                      | This is a reserved character, used when adding more parameters to the query string. |
| results=10             | This is also a parameter name/value pair.                    |

In the above example, name/value pairs in the form of `product=iphone`, `size=32gb` and `color=white`are passed to the server from the URL. This is asking the `www.phoneshop.com` server to narrow down on a product `iphone`, size `32gb` and color `white`. How the server uses these parameters is up to the server side application.  **Because query strings are passed in through the URL, they are only used in HTTP GET requests**

Query strings are great to pass in additional information to the server, however, there are some limits to the use of query strings:

- Query strings have a maximum length. Therefore, if you have a lot of data to pass on, you will not be able to do so with query strings.

- The name/value pairs used in query strings are visible in the URL. For this reason, passing sensitive information like username or password to the server in this manner is not recommended.

- Space and special characters like `&` cannot be used with query strings. They must be URL encoded, which we'll talk about next.

  

  1. **What URL encoding is and when it might be used for?**

     URLs are designed to accept only certain characters in the standard 128-character [ASCII character set](http://en.wikipedia.org/wiki/ASCII). Reserved or unsafe ASCII characters which are not being used for their intended purpose, as well as characters not in this set, have to be encoded. URL encoding serves the purpose of replacing these non-conforming characters with a `%` symbol followed by two hexadecimal digits that represent the [ASCII code](http://www.asciitable.com/) of the character.

     Characters must be encoded if:

     1. They have no corresponding character within the standard [ASCII character set](http://www.asciitable.com/).
     2. The use of the character is unsafe because it may be misinterpreted, or even possibly modified by some systems. For example `%` is unsafe because it can be used for encoding other characters. Other unsafe characters include spaces, quotation marks, the `#` character, `<` and `>`, `{` and `}`, `[` and `]`, and `~`, among others.
     3. The character is reserved for special use within the URL scheme. Some characters are reserved for a special meaning; their presence in a URL serve a specific purpose. Characters such as `/`, `?`, `:`, `@`, and `&` are all reserved and must be encoded. For example `&` is reserved for use as a query string delimiter. `:` is also reserved to delimit host/port components and user/password.

     So what characters can be used safely within a URL? Only alphanumeric and special characters `$-_.+!'()",` and reserved characters when used for their reserved purposes can be used unencoded within a URL. As long as a character is not being used for its reserved purpose, it has to be encoded.

1. **What is www in the URL?**

   What you put into your browser to make an HTTP request.  The server sends back a raw response.  World Wide Web.  Arbitrary prefix 

2. **What is URI?**

   A **Uniform Resource Identifier** (URI), is a string of characters which identifies a particular resource. It is part of a system by which resources should be uniformly **addressed** on the Web. On the [W3C website](https://www.w3.org/Addressing/), the purpose of a URI is described in the following way:

   > The Web is an information space. Human beings have a lot of mental machinery for manipulating, imagining, and finding their way in spaces. URIs are the points in that space.

   The terms URI and URL (Uniform Resource Locator) are often used interchangeably. We'll discuss the distinctions in a later assignment.

3. **What is the difference between scheme and protocol in URL?**

   protocol all caps.. scheme lowercase... scheme doesn't specify which version just general protocol 

4. **What is HTTP?**

   1. The most common client is an application you interact with on a daily basis called a **Web Browser**. Examples of web browsers include Internet Explorer, Firefox, Safari and Chrome, including mobile versions. Web browsers are responsible for issuing HTTP requests and processing the HTTP response in a user-friendly manner onto your screen. Web browsers aren't the only clients around, as there are many tools and applications that can also issue HTTP requests.
   2. text- based protocol from client to server and back
   3. HTTP is at the core of what the web is about, and also at the core of dynamic web applications. Understanding HTTP is central to understanding how modern web applications work and how they're built.

   **Hypertext Transfer Protocol** (HTTP) is the set of rules which provide uniformity to the way resources on the web are transferred between applications. It is a system of rules, a protocol, that serve as a link between applications and the transfer of [hypertext](http://en.wikipedia.org/wiki/Hypertext) documents. Stated differently, it's an agreement, or message format, of how machines communicate with each other. HTTP follows a simple model where a client makes a **request** to a server and waits for a **response**. Hence, it's referred to as a **request response protocol**. 

   * Under your browser's hood lies a collection of files -- CSS, HTML, Javascript, videos, images, etc. -- that makes displaying the page possible. All these files were sent from a **server** to your browser, the **client**, by an application protocol called HTTP (yes, this is why URLs in your browser address bar start with "http://").

5. **What is the role of HTTP?**

   TCP is the protocol that establishes the connection, then HTTP is the command language. Client and server communicate with this language.

   At its core, HTTP is a set of rules concerned with the syntax and  structure of messages exchanged between applications. Working with HTTP  is ultimately about understanding what those rules mean, and knowing how and when to apply them.

   One of the fundamental aspects of HTTP is its Request-Response behavior. 

6. **Explain the client-server model of web interactions, and the role of HTTP as a protocol within that model**

7. **What are HTTP requests and responses? What are the components of each?**

   If you're fuzzy on the previous paragraph, read it again. It's critical to understand that when using a browser, the browser hides a lot of the underlying HTTP request/response cycle from you. Your browser issued the initial `POST` request, got a response with a `Location` header, then issued another request without any action from you, then displayed the response from that second request. Once again, if you were using a pure HTTP tool, you'd see the `Location` response header from the first `POST` request, but the tool would not automatically issue a second request for you. (Some HTTP tools have this ability, if you check the "automatically follow redirects" option.)



Response Header - 

1. **Describe the HTTP request/response cycle.**

   The most important components to understand about an HTTP request are:

   - HTTP method ex/GET
   - path
   - headers
   - message body (for `POST` requests)
     - connection is established via TCP
     - HTTP GET request sent
     - response retrieved
     - TCP connection closed

2. **What is a** s**tate in the context of the 'web'?**

3. **What is** s**tatelessness?**

   A protocol is said to be **stateless** when it's designed in such a way that each request/response pair is completely independent of the previous one. It is important to be aware of HTTP as a stateless protocol and the impact it has on server resources and ease of use. In the context of HTTP, it means that the server does not need to hang on to information, or state, between requests. As a result, when a request breaks en route to the server, no part of the system has to do any cleanup. Both these reasons make HTTP a resilient protocol, as well as a difficult protocol for building stateful applications. Since HTTP, the protocol of the internet, is inherently stateless that means web developers have to work hard to simulate a stateful experience in web applications.

4. **What is a stateful Web Application?**

   When you go to Facebook, for example, and log in, you expect to see the internal Facebook page. That was one complete request/response cycle. You then click on the picture -- another request/response cycle -- but you do not expect to be logged out after that action. If HTTP is stateless, how did the application maintain state and remember that you already input your username and password? In fact, if HTTP is stateless, how does Facebook even know this request came from *you*, and how does it differentiate data from you vs. any other user? There are tricks web developers and frameworks employ to make it seem like the application is stateful, but those tricks are beyond the scope of this book. The key concept to remember is that even though you may feel the application is stateful, underneath the hood, the web is built on HTTP, a stateless protocol. It's what makes the web so resilient, distributed, and hard to control. It's also what makes it so difficult to secure and build on top of.

5. **How can we mimic a stateful application?**

   - Sessions
   - Cookies
   - Asynchronous JavaScript calls, or AJAX
   - One way to accomplish this is by having the server send some form of a unique token to the client. Whenever a client makes a request to that server, the client appends this token as part of the request, allowing the server to identify clients. In web development, we call this unique token that gets passed back and forth the **session identifier**.
   - This mechanism of passing a `session id` back and forth between the client and server creates a sense of persistent connection between requests. Web developers leverage this faux statefulness to build sophisticated applications. Each request, however, is technically stateless and unaware of the previous or the next one.
   - This sort of faux statefulness has several consequences. First, every request must be inspected to see if it contains a session identifier. Second, if this request does, in fact, contain a session id, the server must check to ensure that this session id is still valid. The server needs to maintain some rules with regards to how to handle session expiration and also decide how to store its session data. Third, the server needs to retrieve the session data based on the session id. And finally, the server needs to recreate the application state (e.g., the HTML for a web request) from the session data and send it back to the client as the response.
   - This means that the server has to work very hard to simulate a stateful experience, and every request still gets its own response, even if most of that response is identical to the previous response.

6. **Why HTTP makes it difficult to build a stateful application?**

   This *statelessness* is what makes HTTP and the internet so distributed and difficult to control, but it's also the same ephemeral attribute that makes it difficult for web developers to build **stateful** web applications.

   

7. **How the idea that HTTP is a stateless protocol makes the web difficult to secure?**

   1. Connection is broken once the request/response cycle is complete
   2. This *statelessness* is what makes HTTP and the internet so distributed and difficult to control, but it's also the same ephemeral attribute that makes it difficult for web developers to build **stateful** web applications.

8. **What is a `GET` request and how does it work?**

   Found in method section of chrome developer tools.  **HTTP Request Method**. You can think of this as the verb that tells the server what action to perform on a resource. The two most common HTTP request methods you'll see are `GET` and `POST`.  When you think about retrieving information, think `GET`, which is the most used HTTP request method. In the above diagram, you'll notice almost all of the requests use `GET` to retrieve the resources needed to display the web page.

   - GET requests are used to retrieve a resource, and most links are GETs.
   - The response from a GET request can be anything, but if it's HTML and that HTML references other resources, your browser will automatically request those referenced resources. A pure HTTP tool will not.

9. **How is `GET` request initiated?**

   retrieving data-`GET` requests are initiated by clicking a link or via the address bar of a browser. When you type an address like `https://www.reddit.com` into the address bar of your browser, you're making a `GET` request. You're asking the web browser to go retrieve the resource at that address, which means we've been making `GET` requests throughout this book. The same goes for interacting with links on web applications. The default behavior of a link is to issue a `GET` request to a URL. 

10. **What is the HTTP response body and what do we use it for?**

    The body contains the data that is being transmitted in an HTTP message and is optional. In other words, an HTTP message can be sent with an empty body. When used, the body can contain HTML, images, audio and so on. You can think of the body as the letter enclosed in an envelope, to be posted.

11. **What are the obligatory components of HTTP requests?**

    The most important components to understand about an HTTP request are:

    - HTTP method- GET/ POST/DELETE/LISTEN (Action)- required 

    - path - required 

    - Parameters

    - headers

    - message body (for `POST` requests)

    - ex/. GET /(can be more /zuck) HTTP/1.1

      HOST: WWW.HARVARD.EDU

      ....

      ​	* The HTTP method and the path are required, and form part of what is  known as the start-line or request-line. As of HTTP 1.0, the HTTP  version also forms part of the request-line. The `Host` header is a required component since HTTP 1.1. Parameters, all other headers, and message body are optional.

      Technically speaking the 'path' portion of the request-line is known  as the 'request-URI', and incorporates the actual path to the resource  and the optional parameters if present. In practice, most people simply  refer to this part of the request-line as the 'path'.

      A client MUST send a Host header field in all HTTP/1.1 request messages.

      Ex/

      ```ruby 
      GET / HTTP/1.1
      Host: launchschool.com
      ```

      

12. **What are the obligatory components of HTTP response?**

    The most important parts of an HTTP response are:

    - status code-  only thing Mandatory ex/ 200 OK

    - headers - status and HTTP version - Optional followed by a space 

      - metadata about contents of response ex/ text/html

    - message body, which contains the raw response data (often in HTML)

    - EX/ HTTP/1.1 200 OK

      Content-Type: text/html    =>all a header to see header in terminal type curl -I http://webite/- written in HTML

      ...

13. **Which HTTP method would you use to send sensitive information to a server? Why?**

    Post- pushing data to the server

14. **Describe how would you send a `GET` request to a server and what would happen at each stage.**

    - GET requests are used to retrieve a resource, and most links are GETs.
    - The response from a GET request can be anything, but if it's HTML and that HTML references other resources, your browser will automatically request those referenced resources. A pure HTTP tool will not.
    - `GET` requests are initiated by clicking a link or via the address bar of a browser. When you type an address like `https://www.reddit.com` into the address bar of your browser, you're making a `GET` request. You're asking the web browser to go retrieve the resource at that address, which means we've been making `GET` requests throughout this book. The same goes for interacting with links on web applications. The default behavior of a link is to issue a `GET` request to a URL

15. **Describe how would you send `POST` requests to a server and what is happening at each stage.**

    1. **`GET` requests should only retrieve content from the server.** They can generally be thought of as "read only" operations, however,  there are some subtle exceptions to this rule. For example, consider a  webpage that tracks how many times it is viewed. `GET` is still appropriate since the main content of the page doesn't change.

       **`POST` requests involve changing values that are stored on the server.** Most HTML forms that submit their values to the server will use `POST`. Search forms are a noticeable exception to this rule: they often use `GET` since they are not changing any data on the server, only viewing it

    `POST` is used when you want to initiate some action on the server, or send data to a server. Let's see an example with our HTTP tool: Typically from within a browser, you use `POST` when submitting a form. `POST`requests allow us to send much larger and sensitive data to the server, such as images or videos. For example, say we need to send our username and password to the server for authentication. We could use a `GET` request and send it through query strings. The flaw with this approach is obvious: our credentials become exposed instantly in the URL; that isn't what we want. Using a `POST` request in a form fixes this problem. `POST` requests also help sidestep the query string size limitation that you have with `GET` requests. With `POST` requests, we can send significantly larger forms of information to the server.

16. **What is a status code? What are some of the status codes types? What is the purpose of status codes?**

    Server always responds with a status code- Do I have the files that the client wants?- sends a response yes/no. 3 digit number to let the client know if they were found/not found/error/etc.. 1XX= Informational, 2XX= Successful, 3XX= Redirection, 4XX= Client Error(404 not found), 5XX= Server Error 

    *  The first component we'll look at is the HTTP Status Code. The status code is a three-digit number that the server sends back after recieving a request signifying the status of a request.  The status text displayed next to the status code provides the description of the code. 

17. **Imagine you are using an HTTP tool and you received a status code `302`. What does this status code mean and what happens if you receive a status code like that?**

    3XX Redirection ..Status Code. I don't have it but I'll send you somewhere that does. 

    Status Text = Found 'redirect'

    Meaning = The requested resource has changed temporarily. Usually results in a redirect to another URL

    Resource has been moved. Reroute request from original URL to another.

    When your browser sees a response status code of *302*, it knows that the resource has been moved, and will automatically follow the new re-routed URL in the `Location` response header. In this section, we'll focus on redirects in the context of a Browser and an HTTP tool.

    Ex/

    Say you want to access the account profile at [GitHub](http://www.github.com/), you'll have to go to the address `https://github.com/settings/profile`. However, in order to have access to the profile page, you must first be signed in. If you're not already signed in, the browser will send you to a page to do that. After you enter your credentials, you'll be redirected to the original page you were trying to access. This is a pretty common workflow most web applications employ. Let's see how the browser and the HTTP tool handle that workflow.

18. **How do modern web applications 'remember' state for each client?**

    - Sessions- Actual session data is stored on the server.
    - Cookies- A piece of data that's sent from the server and stored in the client during a request/ response cycle.  aka "HTTP cookie" are small files stored in the browser and contain the session info. Server sends session infoand sets it in your browser cookie on your local computer. Client side cookie is compared with the server-side session data on each request to identify the current session. When you visit the same website again, your session will be recognized bc of the stored cookie with its associated info.  After the client sends a request, the server sends a response with a cookie, the client sends another response with that cookie 
      -  This piece of data will be sent to the server each time you make a request and uniquely identifies you -- or more precisely, it identifies your client, which is your browser. The browser on your computer stores these cookies. Now, if you were to close your browser and shut down your computer, the cookie information would still persist.
      - With the session id now being sent with every request, the server can now uniquely identify this client. When the server receives a request with a session id, the server will look for the associated data based on that id, and in that associated session data is where the server "remembers" the state for that client, or more precisely, for that session id.
      - Where is the session data stored? The simple answer is: on the server *somewhere*. Sometimes, it's just stored in memory, while other times, it could be stored in some persistent storage, like a database or key/value store. Where the session data is actually stored is not too important right now. The most important thing is to understand that the session id is stored on the client, and it is used as a "key" to the session data stored server side. That's how web applications work around the statelessness of HTTP.
      - It is important to be aware of the fact that the id sent with a session is unique and expires in a relatively short time. In this context, it means you'll be required to login again after the session expires. If we log out, the session id information is gone:  To recap, we've seen that the session data is generated and stored on the server-side and the session id is sent to the client in the form of a cookie.
    - Asynchronous JavaScript calls and XML, or AJAX

19. **What role does AJAX play in displaying dynamic content in web applications?**

    Its main feature is that it allows browsers to issue requests and process responses *without a full page refresh*. For example, if you're logged into Facebook, the server has to generate the initial page you see, and the response is a pretty complex and  expensive HTML page that your browser displays. The Facebook server has  to add up all the likes and comments for every photo and status, and  present it in a timeline for you. As we described earlier, it's a very  expensive page to re-generate for every request (remember, every action  you take -- clicking a link, submitting a form -- issues a new request).

    When AJAX is used, all requests sent from the client are performed *asynchronously*, which just means that the page doesn't refresh. Let's see an example by performing some search on google:

    The responses from these requests are being processed by some callback. You can think of a `callback` as a piece of logic you pass on to some function to be executed after a certain event has happened. In this case, the callback is triggered  when the response is returned. You can probably guess that the callback  that's processing these asynchronous requests and responses is updating  the HTML with new search results.

20. **Describe some of the security threats and what can be done to minimize them?**

    THREAT - If a malicious hacker was attached to the same network, they could employ *packet sniffing* techniques to read the messages being sent back and forth. As we  learned previously, requests can contain the session id, which uniquely  identifies you to the server, so if someone else copied this session id, they could craft a request to the server and pose as your client, and  thereby automatically being logged in without even having access to your username or password.

    MINIMIZE THREAT - This is where Secure HTTP, or **HTTPS**, helps. A resource that's accessed by HTTPS will start with `https://` instead of `http://`, and usually be displayed with a lock icon in most browsers: With HTTPS every request/response is encrypted before being transported  on the network. This means if a malicious hacker sniffed out the HTTP  traffic, the information would be encrypted and useless.



​		THREAT - if an attacker gets a hold of the session id, both the attacker and the  user now share the same session and both can access the web application. In session hijacking, the user won't even know an attacker is accessing his or her session without ever even knowing the username or password

​	   MINIMIZE THREAT - 

			* One popular way of solving session hijacking is by resetting sessions.  With authentication systems, this means a successful login must render  an old session id invalid and create a new one. With this in place, on  the next request, the victim will be required to authenticate. At this  point, the altered session id will change, and the attacker will not be  able to have access. Most websites implement this technique by making  sure users authenticate when entering any potentially sensitive area,  such as charging a credit card or deleting the account.
			* Another useful solution is by setting an expiration time on sessions.  Sessions that do not expire give an attacker an infinite amount of time  to pose as the real user. Expiring sessions after, say 30 minutes, gives the attacker a far narrower window to access the app.
			* Finally, as we have already covered, another approach is to use HTTPS across the entire app to minimize the chance that an attacker can get  to the session id.



​		THREAT- Cross-site scripting, or **XSS**. This type of attack  happens when you allow users to input HTML or JavaScript that ends up  being displayed by the site directly.  Attackers can craft ingeniously malicious HTML and JavaScript and be  very destructive to both the server as well as future visitors of this  page. For example, an attacker can use JavaScript to grab the session id of every future visitor of this site and then come back and assume  their identity. It could happen silently without the victims ever  knowing about it. Note that the malicious code would bypass the  same-origin policy because the code lives on the site.

MINIMIZE THREAT - 

	* One way to prevent this kind of attack is by making sure to always  sanitize user input. Eliminate problematic input, such as <script> tags, or disallowing HTML and JavaScript input altogether in favor of a safer format, like Markdown.
	* The second way to guard against XSS is to escape all user input data  when displaying it. If you do need to allow users to input HTML and  JavaScript, then when you print it out, make sure to escape it so that  the browser does not interpret it as code.

 

1. **What is the Same Origin Policy? How it is used to mitigate certain security threats?**

   The same-origin policy is an important concept that permits unrestricted interaction between resources originating from the same origin, but  restricts certain interactions between resources originating from  different origins. What we mean by *origin* here is the combination of a url's scheme, hostname, and port. So `http://mysite.com/doc1` would be considered to have the same origin as `http://mysite.com/doc2`, but a different origin to `https://mysite.com/doc2` (different scheme), `http://mysite.com:4000/doc2` (different port), and `http://anothersite.com/doc2` (different host).

   Same-origin policy doesn't restrict *all* cross-origin requests.  Requests such as linking, redirects, or form submissions to different  origins are typically allowed. Also typically allowed is the embedding  of resources from other origins, such as scripts, css stylesheets,  images and other media, fonts, and iframes. What *is* typically restricted are cross-origin requests where resources are being accessed programmatically using APIs such as `XMLHttpRequest` or `fetch` (the details of which are beyond the scope of this book).   

2. **What determines whether a request should use `GET` or `POST` as its HTTP method?**

3. **What is the relationship between a scheme and a protocol in the context of a URL?**

   Another frequent point of confusion when discussing URLs are the terms *scheme* and *protocol*. When looking at URL Components, we described the component that  prepends the colon and two forward slashes at the start of a URL as the *scheme*.

   You'll often hear this URL component incorrectly referred to as the *protocol*. The source of this confusion is that, although referring to this  component as the protocol is technically incorrect, in the context of a  URL there *is* a relationship between the two things in that the  scheme identifies which protocol should be used to access the resource.  It should be noted that 'protocol' in this sense refers to a 'family' of protocols, rather than a specific protocol version, e.g. `HTTP` rather than `HTTP 1.0` or `HTTP 1.1`.

   One more thing to note when discussing schemes and protocols is that the canonical form of a scheme name is lowercase. The convention is to  refer to scheme names in lowercase, e.g. `http`, and protocol names in uppercase, e.g. HTTP.

4. **In what ways can we pass information to the application server via the URL?**

5. **How insecure HTTP message transfer looks like?**

6. **What services does HTTP provide and what are the particular problems each of them aims to address?**

7. **TLS HANDSHAKE STEPS**

   TLS assumes TCP is being used at the Transport layer, and the TLS Handshake takes place after the TCP Handshake. A step-by-step description of the TLS Handshake process might look something like this:

   1. The TLS Handshake begins with a `ClientHello` message which is sent immediately after the TCP `ACK`. Among other things, this message contains the maximum version of the TLS protocol that the client can support, and a list of Cipher Suites that the client is able to use (we'll discuss Cipher Suites a little later on).
   2. On receiving the `ClientHello` message, the server responds with a message of its own. This message includes a `ServerHello`, which sets the protocol version and Cipher Suite, as well as other related information. As part of this message the server also sends its certificate (which contains its public key), and a `ServerHelloDone` marker which indicates to the client that it has finished with this step of the handshake.
   3. Once the client has received the `ServerHelloDone` marker, it will initiate the key exchange process. It's this key exchange process that ultimately enables both the client and server to securely obtain a copy of the symmetric encryption key that will be used for the bulk of the secure message transfer between the two parties. The exact process for generating the symmetric keys will vary depending on which key exchange algorithm was selected as part of the Cipher Suite (e.g. RSA, Diffie-Hellman, etc). You don't need to worry about the distinctions between these key exchange mechanisms, but as an example RSA works in the following way:
      - The client generates what's known as a 'pre-master secret', encrypts it using the server's public key, and sends it to the server.
      - The server will receive the encrypted 'pre-master secret' and decrypt it using its private key.
      - Both client and server will use the 'pre-master' secret, along with some other pre-agreed parameters, to generate the same symmetric key.
      - As part of the communication which includes the `ClientKeyExchange` message (e.g. the pre-master secret), the client also sends a `ChangeCipherSpec` flag, which tells the server that encrypted communications should now start using the symmetric keys. Additionally this communication includes a `Finished` flag to indicate that the client is now done with the TLS Handshake.
   4. The server also sends a message with `ChangeCipherSpec` and `Finished` flags. The client and server can now begin secure communication using the symmetric key.

   

   ![Graphic illustrating the steps of TLS Handshake](https://da77jsbdz4r05.cloudfront.net/images/ls170/tls-encryption-tls-handshake.png)

   

   As you can see, the TLS Handshake is a fairly complicated process. We certainly don't expect you to memorize every detail of the various steps involved. Instead, try to form a high-level mental model for how it works. Note also that the exact process will vary according to which version of TLS is used. The key points to remember about the TLS Handshake process is that it is used to:

   - Agree which version of TLS to be used in establishing a secure connection.
   - Agree on the various algorithms that will be included in the cipher suite.
   - Enable the exchange of symmetric keys that will be used for message encryption.

   Something you should be aware of is that one of the implications of this complexity is its impact on performance. The TLS handshake can add up to two round-trips of latency (depending on the TLS version) to the establishment of a connection between client and server prior to the point where any application data can be sent. This is on top of the initial round trip resulting from the TCP Handshake.

8. **What is symmetric key encryption? What is it used for?**

   

9. **What is asymmetric key encryption? What is it used for?**

   Happens at TLS Handshake before messages are sent.  Encrypts keys for end to end encryption. 

10. **Describe SSL/TLS encryption process.**

    HTTPS sends messages through a cryptographic protocol called [TLS](http://en.wikipedia.org/wiki/Transport_Layer_Security) for encryption. Earlier versions of HTTPS used `SSL`or Secure Sockets Layer until `TLS` was developed. These cryptographic protocols use certificates to  communicate with remote servers and exchange security keys before data  encryption happens. You can inspect these certificates by clicking on  the padlock icon that appears before the `https://`:

    To securely send messages via HTTP we want both the request *and* the response to be encrypted in a such a way that they can only be decrypted by the intended recipient. The most efficient way to do this is via symmetric key cryptography. If we want to use symmetric keys however, we also need a way to securely exchange the symmetric key.

11. **Describe the pros and cons of TLS Handshake**

    The way in which TLS (Transport Leyer Security) sets up an encrypted connection is via a process known as the TLS Handshake.  The clever thing about TLS is the way that it uses a combination of symmetric and asymmetric cryptography.  The clever thing about TLS is the way that it uses a combination of symmetric and asymmetric cryptography

    ​	Why? Cryptography- techniques to secure communication

      - encryption keys- you can only decipher the message with an encryption key that both sides agree on and copy/ we can now encrypt and decrypt
      - No one else can have the key! How can we exchange this key without anyone else getting it? We must encrypt the encryption key![Simple Alice and Bob graphic illustrating the mechanics of asymmetric key encryption](https://da77jsbdz4r05.cloudfront.net/images/ls170/tls-encryption-asymmetric.png)
      - Asymmetric Key Encryption- 
        - aka public key encyrption uses a pair of keys- a public key and a private key.
        - Unlike the symmetric system where the same key is used to encrypt and decrypt messages, in the asymmetric system the keys in the pair are non-identical: the public key is used to encrypt and the private key to decrypt.
        - The important thing to understand is that messages encrypted with the public key can *only* be decrypted with the private key. The public key is made openly available but the private key is kept in the sole possession of the message receiver.
        - An important thing to note here is that this encryption is primarily intended to work in one direction. Bob can send Alice messages encrypted with the public key which she can then decrypt with the private one. The same key pair would not be used in the other direction for secure communication, since anyone with access to the public key can decrypt the message.

![Simple Alice and Bob graphic illustrating the mechanics of asymmetric key encryption](https://da77jsbdz4r05.cloudfront.net/images/ls170/tls-encryption-asymmetric.png)

1. **Why do we need digital TLS/SSL certificates?**

   1. So we don't interact with a false website.

   2. During the description of the TLS Handshake, we mentioned Cipher Suites a few times. So what exactly is a Cipher Suite?

      A *cipher* is a cryptographic algorithm; in other words they are sets of steps for performing encryption, decryption, and other related tasks. A *cipher suite* is a suite, or set, of ciphers.

      TLS uses different ciphers for different aspects of establishing and maintaining a secure connection. There are many algorithms which can be used for performing the key exchange process, as well as for carrying out authentication, symmetric key encryption, and checking message integrity.

      The algorithms for performing each of these tasks, when combined, form the *cipher suite*. The suite to be used is agreed as part of the TLS Handshake. As part of the `ClientHello` message, the client sends a list of algorithms it supports for each required task, and the server chooses from these according to which algorithms it also supports.

      - The server sends its certificate, which includes its *public* key.
      - The server creates a 'signature' in the form of some data encrypted with the server's *private* key.
      - The signature is transmitted in a message along with the original data from which the signature was created.
      - On receipt of the message, the client decrypts the signature using the server's public key and compares the decrypted data to the original version.
      - If the two versions match then the encrypted version could only have been created by a party in possession of the private key.
      - Following a process such as this we can identify that the server which provided the certificate during the initial part of the TLS Handshake as being in possession of the private key, and therefore the actual owner of the certificate.
        * There's still an issue here though. What's to stop a malicious third-party creating their own key pair and certificate identifying them as, say, a well-known bank? Just as it's possible to create a fake ID card in the real world, it's possible to create a fake digital certificate. How are we to know if a certificate is genuine or not? This is where Certificate Authorities come in.

2. **What is CA hierarchy and what is its role in providing secure message transfer?**

   1. So who exactly are these Certificate Authorities, and why should we trust them? There are different 'levels' of CA. An 'Intermediate CA' can be any company or body authorised by a 'Root CA' to issue certificates on its behalf. A widely-used Intermediate CA is Let's Encrypt, who provide free, automated certificates.
   2. Client software, such as browsers, store a list of these authorities along with their Root Certificates (which includes their public key). When receiving a certificate for checking, the browser can go up the chain to the Root Certificate stored in its list.
   3. The purpose of this chain-like structure is the level of security it provides. The private keys of the Root CAs are kept behind many layers of security in order to be kept as inaccessible as possible. As such they don't issue end-user certificates, but leave that up to the Intermediate CAs. Additionally, if the private key of an Intermediate CA somehow became compromised, the root CA can revoke the certificate for Intermediate, therefore invalidating all of the certificates down the chain from it, and simply issue a new one.

3. **What is Cipher Suites and what do we need it for?**

   During the description of the TLS Handshake, we mentioned Cipher Suites a few times. So what exactly is a Cipher Suite?

   A *cipher* is a cryptographic algorithm; in other words they are sets of steps for performing encryption, decryption, and other related tasks. A *cipher suite* is a suite, or set, of ciphers.

   TLS uses different ciphers for different aspects of establishing and maintaining a secure connection. There are many algorithms which can be used for performing the key exchange process, as well as for carrying out authentication, symmetric key encryption, and checking message integrity.

   The algorithms for performing each of these tasks, when combined, form the *cipher suite*. The suite to be used is agreed as part of the TLS Handshake. As part of the `ClientHello` message, the client sends a list of algorithms it supports for each required task, and the server chooses from these according to which algorithms it also supports.

4. **How does TLS add a security layer to HTTP?**

   1. TLS used to be SSL 

   2. 3 important security services that are provided by TLS:

      * Each of these services are important in their own right, but when combined they provide for very secure message exchange over what is essentially an unsecure channel. Let's look a bit more closely at the nature of these services.

      1. *Encryption*-
         1. a process of encoding a message so that it can only be read by those with an authorized means of decoding the message
         2. See TLS Handshake 
      2. *Authentification*-
         1. a process to verify the identity of a particular party in the message exchange
         2. TLS Authentication is implemented through the use of *Digital Certificates*.
         3. Certificates are *signed* by a *Certificate Authority*, and work on the basis of a *Chain of Trust* which leads to one of a small group of highly trusted *Root CAs*
      3. *Integrity*-
         1. a process to detect whether a message has been interfered with or faked
            1. The main field that interests us in terms of providing message integrity is the `MAC` (*Message Authentication Code*- similar to checksum) field. Note that, though they use the same acronym, the Message Authentication Code is completely unrelated to the MAC Address (media access control address) discussed in an earlier lesson. The intention of the `MAC` field in a TLS record is to add a layer of security by providing a means of checking that the message hasn't been altered or tampered with in transit.
               1. The sender will create what's called a *digest* of the data payload. This is effectively a small amount of data derived from the actual data that will be sent in the message. The digest is created using a specific hashing algorithm combined with a pre-agreed hash value. This hashing algorithm to be used and hash value will have been agreed as part of the TLS Handshake process when the Cipher Suite is negotiated.
               2. The sender will then encrypt the data payload using the symmetric key (as described earlier in the Encryption section), encapsulate it into a TLS record, and pass this record down to the Transport layer to be sent to the other party.
               3. Upon receipt of the message, the receiver will decrypt the data payload using the symmetric key. The receiver will then also create a digest of the payload using the same algorithm and hash value. If the two digests match, this confirms the integrity of the message.

5. **Compare HTTP and HTTPS.**

6. **Does HTTPS use other protocols?**

7. **How do you know a website uses HTTPS?**

8. **Give examples of some protocols that would be used when a user interacts with a banking website. What would be the role of those protocols?**

   1. TLS

9. **What is server-side infrastructure? What are its basic components?**

   A *web server* is typically a server that responds to requests for static assets: files, images, css, javascript, etc. These requests  don't require any data processing, so can be handled by a simple web  server.

   An *application server*, on the other hand, is typically where application or business logic resides, and is where more complicated  requests are handled. This is where your server-side code lives when  deployed.

   The application server will often consult a persistent *data store*, like a relational database, to retrieve or create data. Data stores can also be simple files, key/value stores, document stores and many other  variations, as long as it can save data in some format for later  retrieval and processing.

10. **What is a server? What is its role?**

    Yet taken together as unified concept, the server-side infrastructure in its entirety is the "server" to the client. The word "server" is  severely overloaded, so it's important to keep in mind what exactly  we're talking about at every turn.

11. **What are optimizations that developers can do in order to improve performance and minimize latency?**

    1. Cache 
    2. reduce TCP connections 
    3. Browser Optimization 
    4. Compression techniques
    5. DNS Optimizations 

# Summary

- The *Domain Name System* (DNS) is a distributed database which *translates a domain name* such as `google.com` *to an IP Address* such as `216.58.213.14`.
- A *URI* is an *identifier* for a *particular* resource within an information space.
- A URL is a subset of URI, but the two terms are often used interchangeably.
- URL components include the *scheme*, *host* (or hostname), *port*, *path*, and *query string*.
- *Query strings* are used to *pass additional data* to the server during an HTTP Request. They take the form of *name/value pairs* separated by an `=` sign. Multiple name/value pairs are separated by an `&` sign. The start of the query string is indicated by a `?`.
- *URL encoding* is a technique whereby *certain characters* in a URL are *replaced with an ASCII code*.
- URL encoding is used if a character has no corresponding character in the ASCII set, is unsafe because it is used for encoding other  characters, or is reserved for special use within the url.
- A single HTTP message exchange consists of a *Request* and a *Response*. The exchange generally takes place between a *Client* and a *Server*. The client sends a Request to the server and the server sends back a Response.
- An *HTTP Request* consists of a *request line*, *headers*, and an optional *body*.
- An *HTTP Response* consists of a *status line*, optional *headers*, and an optional *body*.
- *Status codes* are part of the status line in a Response. They indicate the status of the request. There are various categories of  status code.
- HTTP is a *stateless* protocol. This means that each Request/  Response cycle is independent of Request and Responses that came before  or those that come after.
- *Statefulness can be simulated* through techniques which use *session IDs*, *cookies*, and *AJAX*.
- HTTP is *inherently insecure*. Security can be increased by using *HTTPS*, enforcing *Same-origin policy*, and using techniques to prevent *Session Hijacking* and *Cross-site Scripting*.

# Summary

- HTTP is a *text-based* protocol. HTTP Request and Responses involve sending text between the client and server
- In order for the protocol to work, the Request and Response must be structured in such a way that both the client and the server can understand them.
- With HTTP/1.1, the end of the headers is indicated by an *empty line*.
- The `Content-Length` header can be used to indicate the *size of the body*. This can help determine where the HTTP message should end.



# Summary

- *HTTP Requests and Responses* are transferred in *plain text*; as such they are *essentially insecure*.
- We can use the *Transport Layer Security* (TLS) Protocol to add security to HTTP communications.
- *TLS encryption* allows us to *encode messages* so that they can only be read by those with an authorized means of decoding the message
- TLS encryption uses a combination of *Symmetric Key Encryption* and *Asymmetric Key Encryption*. Encryption of the initial key exchange is performed asymmetrically, and subsequent communications are symmetrically encrypted.
- The *TLS Handshake* is the process by which a client and a server *exchange encryption keys*.
- The *TLS Handshake* must be performed before secure data exchange can begin; it involves *several round-trips of latency* and therefore has an *impact on performance*.
- A *cipher suite* is the *agreed set of algorithms* used by the client and server during the secure message exchange.
- *TLS authentication* is a means of *verifying the identity* of a participant in a message exchange.
- TLS Authentication is implemented through the use of *Digital Certificates*.
- Certificates are *signed* by a *Certificate Authority*, and work on the basis of a *Chain of Trust* which leads to one of a small group of highly trusted *Root CAs*.
- The server's certificate is *sent* during the *TLS Handshake* process.
- *TLS Integrity* provides a means of *checking* whether a message has been *altered or interfered with* in transit.
- TLS Integrity is implemented through the use of a *Message Authentication Code* (MAC).



# Summary

- HTTP has changed considerably over the years, and is continuing to change.
- Many of the changes to HTTP are focused on improving performance in response to the ever increasing demands of modern networked applications.
- Latency has a big impact on the performance of networked applications. As developers and software engineers we need to be aware of this impact, and try to mitigate against it through the use of various optimizations.
- In building networked applications, there are tools and techniques available to us that work around or go beyond the limitations of basic HTTP request-response functionality.
- For certain use cases a peer-to-peer architecture may be more appropriate than a client-server architecture.

HTTP and GUI need to be installed locally. Otherwise use AWS Cloud9